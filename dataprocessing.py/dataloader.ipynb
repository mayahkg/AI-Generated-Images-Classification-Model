{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-28T05:12:42.843033Z",
     "start_time": "2025-07-28T05:12:41.481225Z"
    }
   },
   "outputs": [],
   "source": [
    "# Required imports\n",
    "import os\n",
    "import glob\n",
    "import numpy as np\n",
    "import cv2\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-28T05:12:43.610879Z",
     "start_time": "2025-07-28T05:12:43.607548Z"
    }
   },
   "outputs": [],
   "source": [
    "def load_data(paths, image_size, classes):\n",
    "    images = []\n",
    "    labels = []\n",
    "    ids = []\n",
    "    cls = []\n",
    "\n",
    "    print('Reading training images')\n",
    "\n",
    "    # Getting the Image Paths\n",
    "    for fld in classes:  \n",
    "        index = classes.index(fld)\n",
    "        print('Loading {} files (Index: {})'.format(fld, index))\n",
    "        path = os.path.join(paths, fld, '*g')\n",
    "        files = glob.glob(path)\n",
    "\n",
    "        # Resizing the Images\n",
    "        for fl in files:\n",
    "            image = cv2.imread(fl)\n",
    "            image = cv2.resize(image, (image_size, image_size), cv2.INTER_LINEAR)\n",
    "            images.append(image)\n",
    "\n",
    "            # One-Hot Encoding\n",
    "            label = np.zeros(len(classes))\n",
    "            label[index] = 1.0\n",
    "            labels.append(label)\n",
    "            flbase = os.path.basename(fl)\n",
    "            ids.append(flbase)\n",
    "            cls.append(fld)\n",
    "\n",
    "    # Turning into Numpy Arrays\n",
    "    images = np.array(images)\n",
    "    labels = np.array(labels)\n",
    "    ids = np.array(ids)\n",
    "    cls = np.array(cls)\n",
    "\n",
    "    return images, labels, ids, cls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-28T05:21:34.967414Z",
     "start_time": "2025-07-28T05:21:34.965723Z"
    }
   },
   "outputs": [],
   "source": [
    "# paths = \"/Users/mayahkg/Documents/GitHub/AI-Generated-Images-Classification-Model/datasets\"\n",
    "# image_size = 224\n",
    "#classes = [\"AiArt\",\"RealArt\"]\n",
    "\n",
    "def prepare_data(paths, image_size, classes, test_size=0.2, validation_size=0.2, random_state=42):\n",
    "    # Load data\n",
    "    images, labels, ids, cls = load_data(paths, image_size, classes)\n",
    "    \n",
    "    # Split the data into training and testing sets\n",
    "    train_images, test_images, train_labels, test_labels, train_ids, test_ids, train_cls, test_cls = train_test_split(\n",
    "        images, labels, ids, cls, test_size=test_size, random_state=random_state, stratify=labels\n",
    "    )\n",
    "    \n",
    "    # Further split the training set into training and validation sets\n",
    "    train_images, validation_images, train_labels, validation_labels, train_ids, validation_ids, train_cls, validation_cls = train_test_split(\n",
    "        train_images, train_labels, train_ids, train_cls, test_size=validation_size, random_state=random_state, stratify=train_labels\n",
    "    )\n",
    "    \n",
    "    return (train_images, train_labels, train_ids, train_cls,\n",
    "            validation_images, validation_labels, validation_ids, validation_cls,\n",
    "            test_images, test_labels, test_ids, test_cls)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def normalize_data(train_images, validation_images, test_images):\n",
    "\n",
    "    # Ensure inputs are numpy arrays\n",
    "    train_images = np.array(train_images, dtype=np.uint8)\n",
    "    validation_images = np.array(validation_images, dtype=np.uint8)\n",
    "    test_images = np.array(test_images, dtype=np.uint8)\n",
    "    \n",
    "    # Normalize to [0, 1]\n",
    "    train_images = train_images.astype('float32') / 255.0\n",
    "    validation_images = validation_images.astype('float32') / 255.0\n",
    "    test_images = test_images.astype('float32') / 255.0\n",
    "    \n",
    "    return (train_images, validation_images, test_images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DataSet(object):\n",
    "\n",
    "    def __init__(self, images, labels, ids, cls):\n",
    "\n",
    "        self._num_examples = images.shape[0]\n",
    "        \n",
    "        self.images = images\n",
    "        self.labels = labels\n",
    "        self.ids = ids\n",
    "        self.cls = cls\n",
    "        self._epochs_completed = 0\n",
    "        self._index_in_epoch = 0\n",
    "\n",
    "        @property\n",
    "        def images(self):\n",
    "            return self._images\n",
    "\n",
    "        @property\n",
    "        def labels(self):\n",
    "            return self._labels\n",
    "\n",
    "        @property\n",
    "        def ids(self):\n",
    "            return self._ids\n",
    "\n",
    "        @property\n",
    "        def cls(self):\n",
    "            return self._cls\n",
    "\n",
    "        @property\n",
    "        def num_examples(self):\n",
    "            return self._num_examples\n",
    "\n",
    "        @property\n",
    "        def epochs_completed(self):\n",
    "            return self._epochs_completed\n",
    "        \n",
    "        def next_batch(self, batch_size):\n",
    "            start = self._index_in_epoch\n",
    "            self._index_in_epoch += batch_size\n",
    "\n",
    "            if self._index_in_epoch > self._num_examples:\n",
    "                self._epochs_completed += 1\n",
    "                start = 0\n",
    "                self._index_in_epoch = batch_size\n",
    "                assert batch_size <= self._num_examples\n",
    "            end = self._index_in_epoch\n",
    "\n",
    "            return self._images[start:end], self._labels[start:end], self._ids[start:end], self._cls[start:end]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_datasets(train_images, train_labels, train_ids, train_cls, \n",
    "                   validation_images, validation_labels, validation_ids, validation_cls):\n",
    "    class DataSets(object):\n",
    "        pass\n",
    "\n",
    "    data_sets = DataSets()\n",
    "\n",
    "    # Assign DataSet objects to train and valid attributes\n",
    "    data_sets.train = DataSet(train_images, train_labels, train_ids, train_cls)\n",
    "    data_sets.valid = DataSet(validation_images, validation_labels, validation_ids, validation_cls)\n",
    "\n",
    "    return data_sets"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
